{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://m.blog.naver.com/PostView.nhn?blogId=samsjang&logNo=220655420471&proxyReferer=https%3A%2F%2Fwww.google.com%2F\">[코너검출]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* cornerHarris : 코너를 검출할 8비트의 이미지, 이웃창의 크기 1보다 크게, 미분 값을 계산(홀수), 검출기의 감도계수, 결과를 저장할 객체, 경계 외삽법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../data/scenetext01.jpg', cv2.IMREAD_COLOR)\n",
    "corners = cv2.cornerHarris(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY), 2, 3, 0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 800)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corners.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 800, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#좀더 굵어짐, 팽창연산\n",
    "corners = cv2.dilate(corners, None)\n",
    "\n",
    "show_img = np.copy(img)\n",
    "show_img[corners>0.1*corners.max()]=[0,0,255]\n",
    "\n",
    "corners = cv2.normalize(corners, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "show_img = np.hstack((show_img, cv2.cvtColor(corners, cv2.COLOR_GRAY2BGR)))\n",
    "\n",
    "cv2.imshow('Harris corner detector', show_img)\n",
    "if cv2.waitKey(0) == 27:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./CONNER1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* FAST : 이미지에서 특징점을 추출해 내는 다양한 방법이 있지만, 그 속도면에서 아쉬움이 있었고 정확도를 희생하는 대신 빠른 속도로 특징점을 추출하는 방법으로 2006년에 FAST가 처음 제안되었습니다. 이 방법은 인공지능의 기계학습에서도 활용된다고 합니다. 이 방법은 특정 화소 인근의 화소값을 16개 뽑고 특정 화소의 화소값이 인근의 16개의 화소값에 임계치값(t)을 더한 값보다 크거나 임계치값을 뺀 값보다 작은 인근화소의 개수에 따라 특징점인지를 결정하는 매우 단순한 방식입니다. 여기에 더욱 속도를 향상시키기 위해 16개의 인근화소가 아닌 4개의 인근화소를 활용한다거나, 특징점이 비슷한 부분에서 너무 많이 추출되는 것을 방지하기 위해 억제(Non-maximal Suppression)하는 등이 절차가 적용되기도 합니다. 다른 방식에 비해 특징점 추출의 정확도를 떨어지지만 실시간에서 활용할 수 있는 속도를 제공하면서 어느 정도의 특징점 추출 방법으로 사용된다고 합니다.\n",
    "<a href=\"http://www.gisdeveloper.co.kr/?p=6808\">[FAST]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* FastFeatureDete0c0tor : 특징점 추출 -> 쓰레스홀드, 최댑값이 아닌 값을 억제할지를 결정하는 플래그, 이웃 영역의 크기와 점의 임계값 개수 결정모드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast = cv2.FastFeatureDetector_create(30, True, cv2.FAST_FEATURE_DETECTOR_TYPE_9_16)\n",
    "kp = fast.detect(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img = np.copy(img)\n",
    "for p in cv2.KeyPoint_convert(kp):\n",
    "    cv2.circle(show_img, tuple(p), 2, (0, 255, 0), cv2.FILLED)\n",
    "\n",
    "cv2.imshow('FAST corner detector', show_img)\n",
    "if cv2.waitKey(0) == 27:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./fast.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast.setNonmaxSuppression(False)\n",
    "kp = fast.detect(img)\n",
    "\n",
    "for p in cv2.KeyPoint_convert(kp):\n",
    "    cv2.circle(show_img, tuple(p), 2, (0, 255, 0), cv2.FILLED)\n",
    "    \n",
    "cv2.imshow('FAST corner detector', show_img)\n",
    "if cv2.waitKey(0) == 27:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"fast2.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold:  150\n",
      "nonmaxSuppression:  True\n",
      "neighborhood:  2\n",
      "Total Keypoints with nonmaxSuppression:  191\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('../data/scenetext01.jpg', cv2.IMREAD_COLOR)\n",
    " \n",
    "fast = cv2.FastFeatureDetector_create()\n",
    " \n",
    "fast.setThreshold(150)\n",
    "#fast.setNonmaxSuppression(False)\n",
    " \n",
    "kp = fast.detect(img,None)\n",
    "img2=cv2.drawKeypoints(img,kp,None)\n",
    " \n",
    "print(\"Threshold: \", fast.getThreshold())\n",
    "print(\"nonmaxSuppression: \", fast.getNonmaxSuppression())\n",
    "print(\"neighborhood: \", fast.getType())\n",
    "print(\"Total Keypoints with nonmaxSuppression: \", len(kp))\n",
    " \n",
    "cv2.imshow('img2', img2)\n",
    " \n",
    "kp = fast.detect(img,None)\n",
    " \n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"fast3.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
