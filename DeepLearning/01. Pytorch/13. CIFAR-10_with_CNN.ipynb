{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cPWEXDj1GZwi"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "import numpy as np\n",
    "import time\n",
    "from copy import deepcopy # Add Deepcopy for args\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 34462,
     "status": "ok",
     "timestamp": 1548907905528,
     "user": {
      "displayName": "김승수",
      "photoUrl": "",
      "userId": "00478032631106904091"
     },
     "user_tz": -540
    },
    "id": "r9osn1HVGgxU",
    "outputId": "23c51f9b-748f-443e-8eac-f6d76e1b9eef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./dataset', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainset, valset = torch.utils.data.random_split(trainset, [40000, 10000])\n",
    "testset = torchvision.datasets.CIFAR10(root='./dataset', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "partition = {'train': trainset, 'val':valset, 'test':testset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5A2DCvUxGnsb"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, hid_dim, n_layer, act, dropout, use_bn, use_xavier):\n",
    "        super(MLP, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layer = n_layer\n",
    "        self.act = act\n",
    "        self.dropout = dropout\n",
    "        self.use_bn = use_bn\n",
    "        self.use_xavier = use_xavier\n",
    "        \n",
    "        # ====== Create Linear Layers ====== #\n",
    "        self.fc1 = nn.Linear(self.in_dim, self.hid_dim)\n",
    "        \n",
    "        self.linears = nn.ModuleList()\n",
    "        self.bns = nn.ModuleList()\n",
    "        for i in range(self.n_layer-1):\n",
    "            self.linears.append(nn.Linear(self.hid_dim, self.hid_dim))\n",
    "            if self.use_bn:\n",
    "                self.bns.append(nn.BatchNorm1d(self.hid_dim))\n",
    "                \n",
    "        self.fc2 = nn.Linear(self.hid_dim, self.out_dim)\n",
    "        \n",
    "        # ====== Create Activation Function ====== #\n",
    "        if self.act == 'relu':\n",
    "            self.act = nn.ReLU()\n",
    "        elif self.act == 'tanh':\n",
    "            self.act == nn.Tanh()\n",
    "        elif self.act == 'sigmoid':\n",
    "            self.act = nn.Sigmoid()\n",
    "        else:\n",
    "            raise ValueError('no valid activation function selected!')\n",
    "        \n",
    "        # ====== Create Regularization Layer ======= #\n",
    "        self.dropout = nn.Dropout(self.dropout)\n",
    "        if self.use_xavier:\n",
    "            self.xavier_init()\n",
    "          \n",
    "    def forward(self, x):\n",
    "        x = self.act(self.fc1(x))\n",
    "        for i in range(len(self.linears)):\n",
    "            x = self.act(self.linears[i](x))\n",
    "            if self.use_bn:\n",
    "                x = self.bns[i](x)\n",
    "            x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def xavier_init(self):\n",
    "        for linear in self.linears:\n",
    "            nn.init.xavier_normal_(linear.weight)\n",
    "            linear.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xiyev8moQIEl"
   },
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "US83BQgZQT5r"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, model_code, in_channels, out_dim, act, use_bn):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        if act == 'relu':\n",
    "            self.act = nn.ReLU()\n",
    "        elif act == 'sigmoid':\n",
    "            self.act = nn.Sigmoid()\n",
    "        elif act == 'tanh':\n",
    "            self.act = nn.TanH()\n",
    "        else:\n",
    "            raise ValueError(\"Not a valid activation function code\")\n",
    "        \n",
    "        self.layers = self._make_layers(model_code, in_channels, use_bn)\n",
    "        self.classifer = nn.Sequential(nn.Linear(512, 256),\n",
    "                                       self.act,\n",
    "                                       nn.Linear(256, out_dim))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifer(x)\n",
    "        return x\n",
    "        \n",
    "    def _make_layers(self, model_code, in_channels, use_bn):\n",
    "        layers = []\n",
    "        for x in cfg[model_code]:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels=in_channels,\n",
    "                                     out_channels=x,\n",
    "                                     kernel_size=3,\n",
    "                                     stride=1,\n",
    "                                     padding=1)]\n",
    "                if use_bn:\n",
    "                    layers += [nn.BatchNorm2d(x)]\n",
    "                layers += [self.act]\n",
    "                in_channels = x\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ryIjab0NI_JN"
   },
   "outputs": [],
   "source": [
    "class CNN1(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels = 3,\n",
    "                               out_channels = 64,\n",
    "                               kernel_size = 3,\n",
    "                               stride = 1,\n",
    "                               padding = 1)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 64,\n",
    "                               out_channels = 256,\n",
    "                               kernel_size = 5,\n",
    "                               stride = 1,\n",
    "                               padding = 2)\n",
    "        self.act = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size = 2,\n",
    "                                     stride = 2)\n",
    "        self.fc = nn.Linear(65536, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.act(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7bI6A9QxLjtJ"
   },
   "outputs": [],
   "source": [
    "def dimension_check():\n",
    "    net = CNN('VGG11', 3)\n",
    "    x = torch.randn(2, 3, 32, 32)\n",
    "    y = net(x)\n",
    "    print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1109,
     "status": "ok",
     "timestamp": 1548911309395,
     "user": {
      "displayName": "김승수",
      "photoUrl": "",
      "userId": "00478032631106904091"
     },
     "user_tz": -540
    },
    "id": "u4Dbi5X-MDGJ",
    "outputId": "2db0150b-a672-41ca-f87f-9e76b503969f"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 3 required positional arguments: 'out_dim', 'act', and 'use_bn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-bfe4c6172403>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdimension_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-ecf153f3843c>\u001b[0m in \u001b[0;36mdimension_check\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdimension_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'VGG11'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 3 required positional arguments: 'out_dim', 'act', and 'use_bn'"
     ]
    }
   ],
   "source": [
    "dimension_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sz9_iCJWGzGH"
   },
   "outputs": [],
   "source": [
    "def train(net, partition, optimizer, criterion, args):\n",
    "    trainloader = torch.utils.data.DataLoader(partition['train'], \n",
    "                                              batch_size=args.train_batch_size, \n",
    "                                              shuffle=True, num_workers=2)\n",
    "    net.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    train_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_loss = train_loss / len(trainloader)\n",
    "    train_acc = 100 * correct / total\n",
    "    return net, train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DsS6PQvKG17w"
   },
   "outputs": [],
   "source": [
    "def validate(net, partition, criterion, args):\n",
    "    valloader = torch.utils.data.DataLoader(partition['val'], \n",
    "                                            batch_size=args.test_batch_size, \n",
    "                                            shuffle=False, num_workers=2)\n",
    "    net.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_loss = 0 \n",
    "    with torch.no_grad():\n",
    "        for data in valloader:\n",
    "            images, labels = data\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "            outputs = net(images)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss = val_loss / len(valloader)\n",
    "        val_acc = 100 * correct / total\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Imj5-XqbG4tI"
   },
   "outputs": [],
   "source": [
    "def test(net, partition, args):\n",
    "    testloader = torch.utils.data.DataLoader(partition['test'], \n",
    "                                             batch_size=args.test_batch_size, \n",
    "                                             shuffle=False, num_workers=2)\n",
    "    net.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        test_acc = 100 * correct / total\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vu_vScpPG61S"
   },
   "outputs": [],
   "source": [
    "def experiment(partition, args):\n",
    "  \n",
    "    net = CNN(model_code = args.model_code,\n",
    "              in_channels = args.in_channels,\n",
    "              out_dim = args.out_dim,\n",
    "              act = args.act,\n",
    "              use_bn = args.use_bn)\n",
    "    net.cuda()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    if args.optim == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "    elif args.optim == 'RMSprop':\n",
    "        optimizer = optim.RMSprop(net.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "    elif args.optim == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "    else:\n",
    "        raise ValueError('In-valid optimizer choice')\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "        \n",
    "    for epoch in range(args.epoch):  # loop over the dataset multiple times\n",
    "        ts = time.time()\n",
    "        net, train_loss, train_acc = train(net, partition, optimizer, criterion, args)\n",
    "        val_loss, val_acc = validate(net, partition, criterion, args)\n",
    "        te = time.time()\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "        \n",
    "        print('Epoch {}, Acc(train/val): {:2.2f}/{:2.2f}, Loss(train/val) {:2.2f}/{:2.2f}. Took {:2.2f} sec'.format(epoch, train_acc, val_acc, train_loss, val_loss, te-ts))\n",
    "        \n",
    "    test_acc = test(net, partition, args)    \n",
    "    \n",
    "    result = {}\n",
    "    result['train_losses'] = train_losses\n",
    "    result['val_losses'] = val_losses\n",
    "    result['train_accs'] = train_accs\n",
    "    result['val_accs'] = val_accs\n",
    "    result['train_acc'] = train_acc\n",
    "    result['val_acc'] = val_acc\n",
    "    result['test_acc'] = test_acc\n",
    "    return vars(args), result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u6S8kDvhG9zk"
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import json\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "\n",
    "def save_exp_result(setting, result):\n",
    "    exp_name = setting['exp_name']\n",
    "    del setting['epoch']\n",
    "    del setting['test_batch_size']\n",
    "\n",
    "    hash_key = hashlib.sha1(str(setting).encode()).hexdigest()[:6]\n",
    "    filename = './results/{}-{}.json'.format(exp_name, hash_key)\n",
    "    result.update(setting)\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(result, f)\n",
    "\n",
    "    \n",
    "def load_exp_result(exp_name):\n",
    "    dir_path = './results'\n",
    "    filenames = [f for f in listdir(dir_path) if isfile(join(dir_path, f)) if '.json' in f]\n",
    "    list_result = []\n",
    "    for filename in filenames:\n",
    "        if exp_name in filename:\n",
    "            with open(join(dir_path, filename), 'r') as infile:\n",
    "                results = json.load(infile)\n",
    "                list_result.append(results)\n",
    "    df = pd.DataFrame(list_result) # .drop(columns=[])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "50Fc45ykHAnp"
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_acc(var1, var2, df):\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3)\n",
    "    fig.set_size_inches(15, 6)\n",
    "    sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "\n",
    "    sns.barplot(x=var1, y='train_acc', hue=var2, data=df, ax=ax[0])\n",
    "    sns.barplot(x=var1, y='val_acc', hue=var2, data=df, ax=ax[1])\n",
    "    sns.barplot(x=var1, y='test_acc', hue=var2, data=df, ax=ax[2])\n",
    "    \n",
    "    ax[0].set_title('Train Accuracy')\n",
    "    ax[1].set_title('Validation Accuracy')\n",
    "    ax[2].set_title('Test Accuracy')\n",
    "\n",
    "    \n",
    "def plot_loss_variation(var1, var2, df, **kwargs):\n",
    "\n",
    "    list_v1 = df[var1].unique()\n",
    "    list_v2 = df[var2].unique()\n",
    "    list_data = []\n",
    "\n",
    "    for value1 in list_v1:\n",
    "        for value2 in list_v2:\n",
    "            row = df.loc[df[var1]==value1]\n",
    "            row = row.loc[df[var2]==value2]\n",
    "\n",
    "            train_losses = list(row.train_losses)[0]\n",
    "            val_losses = list(row.val_losses)[0]\n",
    "\n",
    "            for epoch, train_loss in enumerate(train_losses):\n",
    "                list_data.append({'type':'train', 'loss':train_loss, 'epoch':epoch, var1:value1, var2:value2})\n",
    "            for epoch, val_loss in enumerate(val_losses):\n",
    "                list_data.append({'type':'val', 'loss':val_loss, 'epoch':epoch, var1:value1, var2:value2})\n",
    "\n",
    "    df = pd.DataFrame(list_data)\n",
    "    g = sns.FacetGrid(df, row=var2, col=var1, hue='type', **kwargs)\n",
    "    g = g.map(plt.plot, 'epoch', 'loss', marker='.')\n",
    "    g.add_legend()\n",
    "    g.fig.suptitle('Train loss vs Val loss')\n",
    "    plt.subplots_adjust(top=0.89) # 만약 Title이 그래프랑 겹친다면 top 값을 조정해주면 됩니다! 함수 인자로 받으면 그래프마다 조절할 수 있겠죠?\n",
    "\n",
    "\n",
    "def plot_acc_variation(var1, var2, df, **kwargs):\n",
    "    list_v1 = df[var1].unique()\n",
    "    list_v2 = df[var2].unique()\n",
    "    list_data = []\n",
    "\n",
    "    for value1 in list_v1:\n",
    "        for value2 in list_v2:\n",
    "            row = df.loc[df[var1]==value1]\n",
    "            row = row.loc[df[var2]==value2]\n",
    "\n",
    "            train_accs = list(row.train_accs)[0]\n",
    "            val_accs = list(row.val_accs)[0]\n",
    "            test_acc = list(row.test_acc)[0]\n",
    "\n",
    "            for epoch, train_acc in enumerate(train_accs):\n",
    "                list_data.append({'type':'train', 'Acc':train_acc, 'test_acc':test_acc, 'epoch':epoch, var1:value1, var2:value2})\n",
    "            for epoch, val_acc in enumerate(val_accs):\n",
    "                list_data.append({'type':'val', 'Acc':val_acc, 'test_acc':test_acc, 'epoch':epoch, var1:value1, var2:value2})\n",
    "\n",
    "    df = pd.DataFrame(list_data)\n",
    "    g = sns.FacetGrid(df, row=var2, col=var1, hue='type', **kwargs)\n",
    "    g = g.map(plt.plot, 'epoch', 'Acc', marker='.')\n",
    "\n",
    "    def show_acc(x, y, metric, **kwargs):\n",
    "        plt.scatter(x, y, alpha=0.3, s=1)\n",
    "        metric = \"Test Acc: {:1.3f}\".format(list(metric.values)[0])\n",
    "        plt.text(0.05, 0.95, metric,  horizontalalignment='left', verticalalignment='center', transform=plt.gca().transAxes, bbox=dict(facecolor='yellow', alpha=0.5, boxstyle=\"round,pad=0.1\"))\n",
    "    g = g.map(show_acc, 'epoch', 'Acc', 'test_acc')\n",
    "\n",
    "    g.add_legend()\n",
    "    g.fig.suptitle('Train Accuracy vs Val Accuracy')\n",
    "    plt.subplots_adjust(top=0.89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1073
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 993063,
     "status": "error",
     "timestamp": 1548912831887,
     "user": {
      "displayName": "김승수",
      "photoUrl": "",
      "userId": "00478032631106904091"
     },
     "user_tz": -540
    },
    "id": "kmL0mGJpHEKh",
    "outputId": "65073ae2-632a-4a9a-dbe0-c13b35de5990"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(act='relu', epoch=10, exp_name='exp1_lr_model_code', in_channels=3, l2=1e-05, lr=0.0001, model_code='VGG11', optim='RMSprop', out_dim=10, test_batch_size=1024, train_batch_size=256, use_bn=True)\n",
      "Epoch 0, Acc(train/val): 39.24/44.82, Loss(train/val) 1.56/1.56. Took 5.94 sec\n",
      "Epoch 1, Acc(train/val): 52.88/55.95, Loss(train/val) 1.26/1.21. Took 5.95 sec\n",
      "Epoch 2, Acc(train/val): 60.75/61.55, Loss(train/val) 1.08/1.08. Took 6.08 sec\n",
      "Epoch 3, Acc(train/val): 67.28/65.54, Loss(train/val) 0.91/0.95. Took 6.03 sec\n",
      "Epoch 4, Acc(train/val): 71.42/67.35, Loss(train/val) 0.80/0.94. Took 6.07 sec\n",
      "Epoch 5, Acc(train/val): 74.81/69.78, Loss(train/val) 0.72/0.87. Took 5.98 sec\n",
      "Epoch 6, Acc(train/val): 78.02/73.45, Loss(train/val) 0.63/0.78. Took 6.06 sec\n",
      "Epoch 7, Acc(train/val): 80.89/74.07, Loss(train/val) 0.55/0.75. Took 6.04 sec\n",
      "Epoch 8, Acc(train/val): 82.71/74.09, Loss(train/val) 0.50/0.74. Took 6.08 sec\n",
      "Epoch 9, Acc(train/val): 84.83/75.53, Loss(train/val) 0.45/0.75. Took 6.12 sec\n",
      "Namespace(act='relu', epoch=10, exp_name='exp1_lr_model_code', in_channels=3, l2=1e-05, lr=0.0001, model_code='VGG13', optim='RMSprop', out_dim=10, test_batch_size=1024, train_batch_size=256, use_bn=True)\n",
      "Epoch 0, Acc(train/val): 35.87/43.70, Loss(train/val) 1.63/1.59. Took 8.27 sec\n",
      "Epoch 1, Acc(train/val): 49.76/52.80, Loss(train/val) 1.33/1.29. Took 8.10 sec\n",
      "Epoch 2, Acc(train/val): 58.12/61.25, Loss(train/val) 1.13/1.06. Took 8.09 sec\n",
      "Epoch 3, Acc(train/val): 65.27/57.43, Loss(train/val) 0.96/1.25. Took 8.16 sec\n",
      "Epoch 4, Acc(train/val): 69.20/65.45, Loss(train/val) 0.86/0.95. Took 8.38 sec\n",
      "Epoch 5, Acc(train/val): 73.06/67.29, Loss(train/val) 0.76/0.93. Took 7.84 sec\n",
      "Epoch 6, Acc(train/val): 76.80/73.54, Loss(train/val) 0.66/0.76. Took 8.02 sec\n",
      "Epoch 7, Acc(train/val): 79.46/74.47, Loss(train/val) 0.59/0.73. Took 8.27 sec\n",
      "Epoch 8, Acc(train/val): 81.45/74.76, Loss(train/val) 0.53/0.73. Took 8.18 sec\n",
      "Epoch 9, Acc(train/val): 83.86/77.04, Loss(train/val) 0.47/0.71. Took 8.17 sec\n",
      "Namespace(act='relu', epoch=10, exp_name='exp1_lr_model_code', in_channels=3, l2=1e-05, lr=1e-05, model_code='VGG11', optim='RMSprop', out_dim=10, test_batch_size=1024, train_batch_size=256, use_bn=True)\n",
      "Epoch 0, Acc(train/val): 53.05/61.52, Loss(train/val) 1.30/1.06. Took 6.04 sec\n",
      "Epoch 1, Acc(train/val): 67.15/66.59, Loss(train/val) 0.92/0.94. Took 5.93 sec\n",
      "Epoch 2, Acc(train/val): 74.72/67.16, Loss(train/val) 0.72/0.94. Took 5.89 sec\n",
      "Epoch 3, Acc(train/val): 80.26/70.00, Loss(train/val) 0.56/0.88. Took 5.86 sec\n",
      "Epoch 4, Acc(train/val): 85.78/68.93, Loss(train/val) 0.41/0.98. Took 5.82 sec\n",
      "Epoch 5, Acc(train/val): 89.89/70.43, Loss(train/val) 0.29/1.01. Took 5.85 sec\n",
      "Epoch 6, Acc(train/val): 93.23/70.24, Loss(train/val) 0.20/1.12. Took 5.74 sec\n",
      "Epoch 7, Acc(train/val): 94.17/71.74, Loss(train/val) 0.17/1.05. Took 5.77 sec\n",
      "Epoch 8, Acc(train/val): 95.15/69.95, Loss(train/val) 0.14/1.17. Took 5.78 sec\n",
      "Epoch 9, Acc(train/val): 96.19/69.19, Loss(train/val) 0.11/1.40. Took 5.78 sec\n",
      "Namespace(act='relu', epoch=10, exp_name='exp1_lr_model_code', in_channels=3, l2=1e-05, lr=1e-05, model_code='VGG13', optim='RMSprop', out_dim=10, test_batch_size=1024, train_batch_size=256, use_bn=True)\n",
      "Epoch 0, Acc(train/val): 52.07/60.55, Loss(train/val) 1.32/1.09. Took 7.89 sec\n",
      "Epoch 1, Acc(train/val): 66.93/67.51, Loss(train/val) 0.92/0.89. Took 7.97 sec\n",
      "Epoch 2, Acc(train/val): 74.91/69.14, Loss(train/val) 0.71/0.88. Took 7.93 sec\n",
      "Epoch 3, Acc(train/val): 80.89/70.61, Loss(train/val) 0.55/0.87. Took 8.00 sec\n",
      "Epoch 4, Acc(train/val): 85.47/71.52, Loss(train/val) 0.42/0.88. Took 7.90 sec\n",
      "Epoch 5, Acc(train/val): 90.30/72.76, Loss(train/val) 0.29/0.88. Took 7.87 sec\n",
      "Epoch 6, Acc(train/val): 92.90/71.41, Loss(train/val) 0.21/1.05. Took 7.89 sec\n",
      "Epoch 7, Acc(train/val): 94.20/72.26, Loss(train/val) 0.17/1.04. Took 7.89 sec\n",
      "Epoch 8, Acc(train/val): 95.83/73.75, Loss(train/val) 0.12/1.08. Took 7.87 sec\n",
      "Epoch 9, Acc(train/val): 96.15/72.62, Loss(train/val) 0.11/1.23. Took 7.86 sec\n"
     ]
    }
   ],
   "source": [
    "# ====== Random Seed Initialization ====== #\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(\"\")\n",
    "args.exp_name = \"exp1_lr_model_code\"\n",
    "\n",
    "# ====== Model ====== #\n",
    "args.model_code = 'VGG11'\n",
    "args.in_channels = 3\n",
    "args.out_dim = 10\n",
    "args.act = 'relu'\n",
    "\n",
    "# ====== Regularization ======= #\n",
    "args.l2 = 0.00001\n",
    "args.use_bn = True\n",
    "\n",
    "# ====== Optimizer & Training ====== #\n",
    "args.optim = 'RMSprop' #'RMSprop' #SGD, RMSprop, ADAM...\n",
    "args.lr = 0.0015\n",
    "args.epoch = 10\n",
    "\n",
    "args.train_batch_size = 256\n",
    "args.test_batch_size = 1024\n",
    "\n",
    "# ====== Experiment Variable ====== #\n",
    "name_var1 = 'lr'\n",
    "name_var2 = 'model_code'\n",
    "list_var1 = [0.0001, 0.00001]\n",
    "list_var2 = ['VGG11', 'VGG13']\n",
    "\n",
    "\n",
    "for var1 in list_var1:\n",
    "    for var2 in list_var2:\n",
    "        setattr(args, name_var1, var1)\n",
    "        setattr(args, name_var2, var2)\n",
    "        print(args)\n",
    "                \n",
    "        setting, result = experiment(partition, deepcopy(args))\n",
    "        save_exp_result(setting, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 886
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2404,
     "status": "ok",
     "timestamp": 1548912900634,
     "user": {
      "displayName": "김승수",
      "photoUrl": "",
      "userId": "00478032631106904091"
     },
     "user_tz": -540
    },
    "id": "WTUdQrQYIgFp",
    "outputId": "d43c983b-8609-487d-96c9-ae2fa4110fe4"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-9d7c6c913ef8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplot_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplot_loss_variation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#sharey를 True로 하면 모둔 subplot의 y축의 스케일이 같아집니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplot_acc_variation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargin_titles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#margin_titles를 True로 하면 그래프의 가장자리에 var1과 var2 값이 표시되고 False로 하면 각 subplot 위에 표시됩니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-c895bf21b11e>\u001b[0m in \u001b[0;36mplot_loss_variation\u001b[0;34m(var1, var2, df, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mvalue2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mtrain_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "var1 = 'lr'\n",
    "var2 = 'model_code'\n",
    "df = load_exp_result('exp1')\n",
    "\n",
    "plot_acc(var1, var2, df)\n",
    "plot_loss_variation(var1, var2, df, sharey=False) #sharey를 True로 하면 모둔 subplot의 y축의 스케일이 같아집니다.\n",
    "plot_acc_variation(var1, var2, df, margin_titles=True, sharey=True) #margin_titles를 True로 하면 그래프의 가장자리에 var1과 var2 값이 표시되고 False로 하면 각 subplot 위에 표시됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RS7Tj2WuZs-r"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Lab7_CIFAR-10_with_CNN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
