{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "image = np.array([[[[1], [2], [3]],\n",
    "                   [[4], [5], [6]],\n",
    "                   [[7], [8], [9]]]], dtype = np.float32)\n",
    "print(image.shape)\n",
    "plt.imshow(image.reshape(3,3), cmap='Greys')\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "print(\"image.shape\", image.shape)\n",
    "w_filter = tf.constant([[[[1.]],[[1.]]],\n",
    "                      [[[1.]],[[1.]]]])\n",
    "print(\"filter.shape\",w_filter.shape)\n",
    "conv2d = tf.nn.conv2d(input=image,filter=w_filter,strides=[1,1,1,1],padding='VALID')\n",
    "conv2d_img = conv2d.eval()\n",
    "print(\"conv2d_img.shape\",conv2d_img.shape)\n",
    "print(conv2d_img.reshape(2,2))\n",
    "plt.imshow(conv2d_img.reshape(2,2),cmap='Greys')\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "image=np.arange(1,10,dtype=np.float32).reshape(1,3,3,1)\n",
    "print(\"image.shape\", image.shape)\n",
    "w_filter = tf.constant(np.ones(4,dtype=np.float32).reshape(2,2,1,1))\n",
    "print(\"filter.shape\",w_filter.shape)\n",
    "conv2d = tf.nn.conv2d(input=image,filter=w_filter,strides=[1,1,1,1],padding='VALID')\n",
    "conv2d_img = conv2d.eval()\n",
    "print(\"conv2d_img.shape\",conv2d_img.shape)\n",
    "print(conv2d_img.reshape(2,2))\n",
    "plt.imshow(conv2d_img.reshape(2,2),cmap='Greys')\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "image = np.arange(1,50,dtype=np.float32).reshape(1,7,7,1)\n",
    "w_filter = tf.constant(np.full((3,3),2, dtype=np.float32).reshape(3, 3, 1, 1))\n",
    "conv2d = tf.nn.conv2d(input=image,filter=w_filter,strides=[1,2,2,1],padding='VALID')\n",
    "conv2d_img = conv2d.eval()\n",
    "\n",
    "plt.imshow(conv2d_img.reshape(3,3),cmap='Greys')\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess =tf.InteractiveSession()\n",
    "image = np.arange(1,10,dtype=np.float32).reshape(1,3,3,1)\n",
    "w_filter = tf.constant(np.ones(4,dtype=np.float32).reshape(2,2,1,1))\n",
    "conv2d_1 = tf.nn.conv2d(input=image,filter=w_filter,strides=[1,1,1,1], padding='VALID')\n",
    "conv2d_2 = tf.nn.conv2d(input=image,filter=w_filter,strides=[1,1,1,1], padding='SAME')\n",
    "print(conv2d_1.eval().reshape(2,2))\n",
    "print(conv2d_2.eval().reshape(3,3))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "image = np.ones(25,dtype=np.float32).reshape(1,5,5,1)\n",
    "w_filter = tf.constant(np.ones(9, dtype=np.float32).reshape(3, 3, 1, 1))\n",
    "conv2d_2 = tf.nn.conv2d(input=image, filter=w_filter, strides=[1, 1, 1, 1], padding='SAME')\n",
    "print(conv2d_2.eval().reshape(5,5))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "image = np.ones(11*11,dtype=np.float32).reshape(1,11,11,1)\n",
    "w_filter = tf.constant(np.ones(6*6,dtype=np.float32).reshape(6,6,1,1))\n",
    "conv_2d_1 = tf.nn.conv2d(input=image,filter=w_filter,strides=[1,4,4,1],padding='VALID')\n",
    "conv_2d_2 = tf.nn.conv2d(input=image,filter=w_filter,strides=[1,4,4,1],padding='SAME')\n",
    "print(conv_2d_1)\n",
    "print(conv_2d_2)\n",
    "print (conv_2d_1.eval().reshape(2,2))\n",
    "print (conv_2d_2.eval().reshape(3,3))\n",
    "# print(conv_2d_2.eval())\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "image = np.arange(1,17,dtype=np.float32).reshape(1,4,4,1)\n",
    "max_pool = tf.nn.max_pool(image, ksize=[1,2,2,1],strides=[1,2,2,1],padding='VALID')\n",
    "avg_pool = tf.nn.avg_pool(image, ksize=[1,2,2,1],strides=[1,2,2,1],padding='VALID')\n",
    "\n",
    "print(max_pool.eval().shape)\n",
    "print(max_pool.eval().reshape(2,2))\n",
    "print(avg_pool.eval().reshape(2,2))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "image = np.arange(1,37,dtype=np.float32).reshape(1,6,6,1)\n",
    "max_pool = tf.nn.max_pool(image, ksize=[1,5,5,1],strides=[1,4,4,1],padding='SAME')\n",
    "max_pool_v = tf.nn.max_pool(image, ksize=[1,5,5,1],strides=[1,4,4,1],padding='VALID')\n",
    "avg_pool = tf.nn.avg_pool(image, ksize=[1,5,5,1],strides=[1,4,4,1],padding='SAME')\n",
    "avg_pool_v = tf.nn.avg_pool(image, ksize=[1,5,5,1],strides=[1,4,4,1],padding='VALID')\n",
    "print(max_pool.eval().shape)\n",
    "print(avg_pool.eval().shape)\n",
    "print(max_pool_v.eval().shape)\n",
    "print(avg_pool_v.eval().shape)\n",
    "\n",
    "\n",
    "print(max_pool.eval().reshape(2,2))\n",
    "print(avg_pool.eval().reshape(2,2))\n",
    "\n",
    "print(max_pool_v.eval().reshape(1,1))\n",
    "print(avg_pool_v.eval().reshape(1,1))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서플로우에서는 필터에 넣는 파라미터가 넘파이의 쉐이프와 다르므로 swapaxes함수를 이용하여 바꾸어준다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(행,열,인,아웃)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filter= np.array([[[[1,1],[1,1]],[[2,2],[2,2]],[[3,3],[3,3]]]])\n",
    "print(filter.shape)\n",
    "filter = np.swapaxes(filter,0,2)\n",
    "filter = np.swapaxes(filter,1,3)\n",
    "print(filter.shape)\n",
    "print(filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "image = np.arange(1,10,dtype=np.float32).reshape(1,3,3,1)\n",
    "w_filter = np.array([1,1,1,1,2,2,2,2,3,3,3,3],dtype=np.float32).reshape(1,3,2,2)\n",
    "w_filter = np.swapaxes(w_filter,0,2)\n",
    "w_filter = np.swapaxes(w_filter,1,3)\n",
    "conv2d = tf.nn.conv2d(input = image, filter=w_filter,strides=[1,1,1,1],padding='SAME')\n",
    "conv2d_image = conv2d.eval()\n",
    "print(conv2d_image.shape)\n",
    "conv2_image = np.swapaxes(conv2d_image,0,3)\n",
    "print(\"conv2d_img.shape\",conv2_image.shape)\n",
    "print(conv2_image)\n",
    "\n",
    "sess.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mnist.train.images[0].reshape(28,28)\n",
    "print(mnist.train.labels[0])\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "img = img.reshape(1,28,28,1)\n",
    "w_filter= np.random.random((3,3,1,5))\n",
    "conv2d = tf.nn.conv2d(img,w_filter,strides=[1,2,2,1],padding='SAME')\n",
    "print(conv2d)\n",
    "conv2d_img = conv2d.eval()\n",
    "conv2d_img = np.swapaxes(conv2d_img,0,3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    plt.subplot(1,5,i+1),plt.imshow(one_img.reshape(14,14),cmap='gray')\n",
    "sess.close()\n",
    "print(w_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "img = img.reshape(1,28,28,1)\n",
    "w_filter= np.random.random((3,3,1,5))-0.5\n",
    "conv2d = tf.nn.conv2d(img,w_filter,strides=[1,2,2,1],padding='SAME')\n",
    "print(conv2d)\n",
    "conv2d_img = conv2d.eval()\n",
    "conv2d_img = np.swapaxes(conv2d_img,0,3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    plt.subplot(1,5,i+1),plt.imshow(one_img.reshape(14,14),cmap='gray')\n",
    "sess.close()\n",
    "print(w_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "img = img.reshape(1,28,28,1)\n",
    "w_filter = np.random.random((3,3,1,5)) - 0.5\n",
    "conv2d = tf.nn.conv2d(img, w_filter, strides=[1, 2, 2, 1], padding='SAME')\n",
    "conv2d_img = conv2d.eval()\n",
    "conv2d_img = tf.nn.relu(conv2d_img).eval()\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    plt.subplot(1,5,i+1), plt.imshow(one_img.reshape(14,14), cmap='gray')\n",
    "    \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "img = img.reshape(1,28,28,1)\n",
    "w_filter = np.random.random((3,3,1,5)) - 0.5\n",
    "conv2d = tf.nn.conv2d(img, w_filter, strides=[1, 2, 2, 1], padding='SAME')\n",
    "conv2d_img = conv2d.eval()\n",
    "conv2d_img = tf.nn.leaky_relu(conv2d_img).eval()\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    plt.subplot(1,5,i+1), plt.imshow(one_img.reshape(14,14), cmap='gray')\n",
    "    \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\p\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-124fb748f8a0>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\p\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\p\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\p\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\p\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\p\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(777)\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_14:0\", dtype=float32) Tensor(\"Placeholder_15:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "traning_epochs = 5\n",
    "batch_size = 100\n",
    "\n",
    "X= tf.placeholder(tf.float32,[None,784])\n",
    "X=tf.placeholder(tf.float32)\n",
    "X_img = tf.reshape(X,[-1,28,28,1])\n",
    "Y = tf.placeholder(tf.float32,[None,10])\n",
    "print(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_3:0' shape=(3, 3, 1, 32) dtype=float32_ref> Tensor(\"Conv2D_2:0\", shape=(?, 28, 28, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "W1 = tf.Variable(tf.random_normal([3,3,1,32],stddev=0.01))\n",
    "L1 = tf.nn.conv2d(X_img,W1,strides=[1,1,1,1],padding='SAME')\n",
    "print(W1,L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MaxPool_2:0' shape=(?, 14, 14, 32) dtype=float32>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_4:0' shape=(3, 3, 32, 64) dtype=float32_ref> Tensor(\"Conv2D_3:0\", shape=(?, 14, 14, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "W2 = tf.Variable(tf.random_normal([3,3,32,64],stddev=0.01))\n",
    "L2 = tf.nn.conv2d(L1,W2,strides=[1,1,1,1],padding='SAME')\n",
    "print(W2,L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_3:0' shape=(?, 14, 14, 64) dtype=float32>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L2=tf.nn.relu(L2)\n",
    "L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MaxPool_3:0' shape=(?, 7, 7, 64) dtype=float32>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L2 = tf.nn.max_pool(L2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_3:0' shape=(?, 3136) dtype=float32>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ?\n",
    "L2_flat = tf.reshape(L2,shape=[-1,7*7*64])\n",
    "L2_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable W3 already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"C:\\Users\\p\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1768, in __init__\n    self._traceback = tf_stack.extract_stack()\n  File \"C:\\Users\\p\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3272, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\p\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-161-e0f768ff4ba0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mW3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"W3\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxavier_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m   1482\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1483\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1484\u001b[1;33m       aggregation=aggregation)\n\u001b[0m\u001b[0;32m   1485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m   1232\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1233\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1234\u001b[1;33m           aggregation=aggregation)\n\u001b[0m\u001b[0;32m   1235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1236\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    536\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 538\u001b[1;33m           aggregation=aggregation)\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[1;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    490\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 492\u001b[1;33m           aggregation=aggregation)\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[1;31m# Set trainable value based on synchronization value.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    857\u001b[0m                          \u001b[1;34m\"reuse=tf.AUTO_REUSE in VarScope? \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[1;32m--> 859\u001b[1;33m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[0;32m    860\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Variable W3 already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"C:\\Users\\p\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1768, in __init__\n    self._traceback = tf_stack.extract_stack()\n  File \"C:\\Users\\p\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3272, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\p\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "W3 = tf.get_variable(\"W3\",shape=[7*7*64,10],initializer=tf.contrib.layers.xavier_initializer())\n",
    "print(W3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable_5:0' shape=(10,) dtype=float32_ref>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b= tf.Variable(tf.random_normal([10]))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits =tf.matmul(L2_flat,W3) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mean:0\", shape=(), dtype=float32) name: \"Adam\"\n",
      "op: \"NoOp\"\n",
      "input: \"^Adam/update_Variable/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_1/ApplyAdam\"\n",
      "input: \"^Adam/update_W3/ApplyAdam\"\n",
      "input: \"^Adam/update_Variable_2/ApplyAdam\"\n",
      "input: \"^Adam/Assign\"\n",
      "input: \"^Adam/Assign_1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "print(cost,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime\n"
     ]
    }
   ],
   "source": [
    "print('Learning started. It takes sometime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.345577185\n",
      "Epoch: 0002 cost = 0.091736604\n",
      "Epoch: 0003 cost = 0.068284046\n",
      "Epoch: 0004 cost = 0.056339833\n",
      "Epoch: 0005 cost = 0.047010720\n",
      "Learning Finished : \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(traning_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples/batch_size)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y:batch_ys}\n",
    "        c,_ = sess.run([cost,optimizer],feed_dict=feed_dict)\n",
    "        avg_cost += c/ total_batch\n",
    "    print('Epoch:','%04d' % (epoch+1),'cost =','{:.9f}'.format(avg_cost))\n",
    "print('Learning Finished : ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9841\n",
      "Label: [6]\n",
      "Prediction: [6]\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits,1),tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:',sess.run(accuracy,feed_dict={\n",
    "    X: mnist.test.images, Y:mnist.test.labels}))\n",
    "\n",
    "r = random.randint(0,mnist.test.num_examples -1 )\n",
    "print(\"Label:\", sess.run(tf.argmax(mnist.test.labels[r:r+1],1)))\n",
    "print(\"Prediction:\",sess.run(\n",
    "    tf.argmax(logits,1) , feed_dict={\n",
    "        X: mnist.test.images[r:r+1]\n",
    "    }\n",
    "))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2677"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(mnist.test.labels[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.31764707,\n",
      "       0.8862746 , 0.9215687 , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.12941177, 0.8705883 , 0.9960785 , 0.9176471 ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.21176472, 0.8745099 ,\n",
      "       0.9960785 , 0.95294124, 0.28627452, 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.42352945, 0.9921569 , 0.9960785 , 0.7725491 , 0.18431373,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.23137257, 0.9843138 , 0.9960785 ,\n",
      "       0.9215687 , 0.25490198, 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.13333334,\n",
      "       0.882353  , 0.9960785 , 0.95294124, 0.17254902, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.61960787, 0.9960785 , 0.9725491 ,\n",
      "       0.1137255 , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.2627451 ,\n",
      "       0.94117653, 0.9490197 , 0.29411766, 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.03529412, 0.8000001 , 0.9960785 , 0.6156863 ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.5529412 ,\n",
      "       0.9960785 , 0.73333335, 0.14901961, 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.1137255 , 0.92549026, 0.9960785 , 0.41176474,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.01960784, 0.7372549 ,\n",
      "       0.9960785 , 0.9568628 , 0.45098042, 0.8235295 , 0.9803922 ,\n",
      "       0.9803922 , 0.83921576, 0.3372549 , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.10588236, 0.9960785 , 0.9960785 , 0.93725497,\n",
      "       0.9607844 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
      "       0.9686275 , 0.52156866, 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.32156864,\n",
      "       0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9725491 ,\n",
      "       0.8745099 , 0.8745099 , 0.9176471 , 0.9960785 , 0.854902  ,\n",
      "       0.10588236, 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.50980395, 0.9960785 , 0.9960785 ,\n",
      "       0.9960785 , 0.6901961 , 0.227451  , 0.        , 0.        ,\n",
      "       0.10196079, 0.9568628 , 0.9960785 , 0.5058824 , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.8470589 , 1.        , 0.9960785 , 0.9960785 , 0.23529413,\n",
      "       0.        , 0.        , 0.        , 0.37647063, 0.9686275 ,\n",
      "       0.9960785 , 0.4784314 , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.50980395, 0.9960785 ,\n",
      "       0.9960785 , 0.9960785 , 0.46274513, 0.        , 0.        ,\n",
      "       0.32941177, 0.9215687 , 0.9960785 , 0.78823537, 0.03529412,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.28235295, 0.86274517, 0.9960785 , 0.9960785 ,\n",
      "       0.882353  , 0.8588236 , 0.8588236 , 0.9960785 , 0.9960785 ,\n",
      "       0.94117653, 0.21568629, 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.37254903, 0.9725491 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
      "       0.9960785 , 0.9960785 , 0.9176471 , 0.34509805, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.3803922 ,\n",
      "       0.9960785 , 0.8235295 , 0.5882353 , 0.5882353 , 0.35686275,\n",
      "       0.11764707, 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        ], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print([mnist.test.images[r]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2222)\n",
    "X = np.array([1,2,4])\n",
    "Y = np.array([2,4,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "W=np.random.random([1])\n",
    "hypothesis = W*X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X,Y,'o')\n",
    "plt.plot(X,hypothesis)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.71101451 -3.42202903 -6.84405806]\n",
      "-11.97710160165343\n"
     ]
    }
   ],
   "source": [
    "cost = hypothesis - Y\n",
    "print(cost)\n",
    "print(cost.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2222)\n",
    "X = np.array([1,2,4])\n",
    "Y = np.array([2,4,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "W=np.random.random([1])\n",
    "hypothesis = W*X\n",
    "cost = hypothesis - Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.27279982 -2.54559964 -5.09119928]\n",
      "8.909598742500547\n",
      "34.020407036728855\n"
     ]
    }
   ],
   "source": [
    "print(cost)\n",
    "print(np.abs(cost).sum())\n",
    "print((cost**2).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 절대값과 제곱의 차이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2222)\n",
    "X = np.array([1,2,4])\n",
    "Y = np.array([2,4,8])\n",
    "\n",
    "W_val = []\n",
    "cost_val = []\n",
    "cost_val2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "for W in range(-30,50):\n",
    "    W /= 10 # x축값 만들기\n",
    "    hypothesis = W*X\n",
    "    cost = hypothesis - Y\n",
    "    W_val.append(W)\n",
    "    cost_val.append((cost**2).sum())\n",
    "    cost_val2.append(np.abs(cost).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(2,1,1)\n",
    "plt.plot(W_val,cost_val)\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(W_val,cost_val2)\n",
    "\n",
    "3plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 미분 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sp.symbols('x')\n",
    "y = sp.symbols('y')\n",
    "f = x*sp.sin(x)+y\n",
    "diff_x = sp.diff(f,x)\n",
    "diff_y = sp.diff(f,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x*cos(x) + sin(x)\n"
     ]
    }
   ],
   "source": [
    "print(diff_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(diff_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos(1) + sin(1)\n"
     ]
    }
   ],
   "source": [
    "print(diff_x.subs({x:1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([1,2,4])\n",
    "Y = np.array([2,4,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.random.random([1])\n",
    "cost = (np.sum((X*W-Y)**2))/X.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_W = sp.symbols('W')\n",
    "sp_cost = (np.sum((X*sp_W - Y))**2) / X.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=sp.diff(sp_cost,sp_W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff function: 98*W/3 - 196/3\n",
      "d/dw(func(1)): -98/3\n",
      "d/dw(func(1.5)): -16.3333333333333\n",
      "d/dw(func(1.8)): -6.53333333333333\n",
      "d/dw(func(1.9)): -3.26666666666667\n",
      "w , d/dw(func(w)): [0.72706081] -41.5826802967167\n"
     ]
    }
   ],
   "source": [
    "print('diff function:',f)\n",
    "print('d/dw(func(1)):',f.subs({sp_W:1}))\n",
    "print('d/dw(func(1.5)):',f.subs({sp_W:1.5}))\n",
    "print('d/dw(func(1.8)):',f.subs({sp_W:1.8}))\n",
    "print('d/dw(func(1.9)):',f.subs({sp_W:1.9}))\n",
    "print('w , d/dw(func(w)):',W,f.subs({sp_W:W}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W, d/dw(func(W)) : [1.14298145429280] -27.9959391597684\n",
      "W, d/dw(func(W)) : [1.42294084589049] -18.8505990342440\n",
      "W, d/dw(func(W)) : [1.61144683623293] -12.6927366830577\n",
      "W, d/dw(func(W)) : [1.73837420306351] -8.54644269992549\n",
      "W, d/dw(func(W)) : [1.82383863006276] -5.75460475128317\n",
      "W, d/dw(func(W)) : [1.88138467757559] -3.87476719919733\n",
      "W, d/dw(func(W)) : [1.92013234956757] -2.60900991412620\n",
      "W, d/dw(func(W)) : [1.94622244870883] -1.75673334217831\n",
      "W, d/dw(func(W)) : [1.96378978213061] -1.18286711706672\n",
      "W, d/dw(func(W)) : [1.97561845330128] -0.796463858824922\n",
      "W, d/dw(func(W)) : [1.98358309188953] -0.536285664942113\n",
      "W, d/dw(func(W)) : [1.98894594853895] -0.361099014394370\n",
      "W, d/dw(func(W)) : [1.99255693868289] -0.243140003025545\n",
      "W, d/dw(func(W)) : [1.99498833871315] -0.163714268703856\n",
      "W, d/dw(func(W)) : [1.99662548140019] -0.110234274260606\n",
      "W, d/dw(func(W)) : [1.99772782414279] -0.0742244113354786\n",
      "W, d/dw(func(W)) : [1.99847006825615] -0.0499777702992219\n",
      "W, d/dw(func(W)) : [1.99896984595914] -0.0336516986681374\n",
      "W, d/dw(func(W)) : [1.99930636294582] -0.0226588104365391\n",
      "W, d/dw(func(W)) : [1.99953295105019] -0.0152569323606002\n"
     ]
    }
   ],
   "source": [
    "X = np.array([1,2,4])\n",
    "Y = np.array([2,4,8])\n",
    "np.random.seed(2222)\n",
    "W = np.random.random([1])\n",
    "sp_W = sp.symbols('W')\n",
    "cost = (np.sum((X*W - Y))**2) / X.size\n",
    "\n",
    "sp_W = sp.symbols('W')\n",
    "sp_cost = (np.sum((X*sp_W - Y))**2)/X.size\n",
    "f = sp.diff(sp_cost , sp_W)\n",
    "learning_rate=0.01\n",
    "for step in range(20):\n",
    "    W = W - learning_rate * f.subs({sp_W:W})\n",
    "    print('W, d/dw(func(W)) :',W,f.subs({sp_W:W}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = np.array([1,2,4])\n",
    "Y = np.array([2,4,8])\n",
    "np.random.seed(2222)\n",
    "W = np.random.random([1])\n",
    "sp_W = sp.symbols('W')\n",
    "cost = (np.sum((X*W - Y))**2) / X.size\n",
    "\n",
    "sp_W = sp.symbols('W')\n",
    "sp_cost = (np.sum((X*sp_W - Y))**2)/X.size\n",
    "f = sp.diff(sp_cost , sp_W)\n",
    "learning_rate=0.01\n",
    "for step in range(20):\n",
    "    W = W - learning_rate * f.subs({sp_W:W})\n",
    "    \n",
    "hypothesis = W*X\n",
    "\n",
    "plt.plot(X,Y,'o')\n",
    "plt.plot(X,hypothesis)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3시간 놀명 행복지수는 [5.99859885315056]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([1,2,4])\n",
    "Y = np.array([2,4,8])\n",
    "np.random.seed(2222)\n",
    "W = np.random.random([1])\n",
    "sp_W = sp.symbols('W')\n",
    "cost = (np.sum((X*W - Y))**2) / X.size\n",
    "\n",
    "sp_W = sp.symbols('W')\n",
    "sp_cost = (np.sum((X*sp_W - Y))**2)/X.size\n",
    "f = sp.diff(sp_cost , sp_W)\n",
    "learning_rate=0.01\n",
    "for step in range(20):\n",
    "    W = W - learning_rate * f.subs({sp_W:W})\n",
    "    \n",
    "hypothesis = (lambda input : input*W)\n",
    "/\n",
    "print('3시간 놀명 행복지수는',hypothesis(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(2222)\n",
    "learning_rate = 0.01\n",
    "X_data = np.array([1,2,4])\n",
    "Y_data = np.array([2,4,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32,[3])\n",
    "Y = tf.placeholder(tf.float32,[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([1]),name='weight')\n",
    "hypothesis = X*W\n",
    "cost = tf.reduce_mean(tf.square(hypothesis-Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "'sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:  1 cost : 37.144596 W : [0.01894161]\n",
      "step:  2 cost : 27.472145 W : [0.29628977]\n",
      "step:  3 cost : 20.3184 W : [0.53480923]\n",
      "step:  4 cost : 15.027489 W : [0.73993593]\n",
      "step:  5 cost : 11.114331 W : [0.9163449]\n",
      "step:  6 cost : 8.220159 W : [1.0680566]\n",
      "step:  7 cost : 6.07963 W : [1.1985286]\n",
      "step:  8 cost : 4.4964943 W : [1.3107346]\n",
      "step:  9 cost : 3.3256073 W : [1.4072318]\n",
      "step:  10 cost : 2.4596188 W : [1.4902194]\n",
      "step:  11 cost : 1.8191341 W : [1.5615886]\n",
      "step:  12 cost : 1.3454317 W : [1.6229663]\n",
      "step:  13 cost : 0.99508095 W : [1.675751]\n",
      "step:  14 cost : 0.735962 W : [1.7211459]\n",
      "step:  15 cost : 0.54431736 W : [1.7601855]\n",
      "step:  16 cost : 0.40257704 W : [1.7937595]\n",
      "step:  17 cost : 0.29774612 W : [1.8226331]\n",
      "step:  18 cost : 0.220213 W : [1.8474646]\n",
      "step:  19 cost : 0.16286942 W : [1.8688195]\n",
      "step:  20 cost : 0.12045831 W : [1.8871847]\n"
     ]
    }
   ],
   "source": [
    "for step in range(20):\n",
    "    cost_val, W_val, _ = sess.run([cost,W,train],feed_dict={X:X_data,Y:Y_data})\n",
    "    print(\"step: \",step+1,\"cost :\",cost_val,\"W :\",W_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3시간 놀면 행복지수는 [5.6615543]\n"
     ]
    }
   ],
   "source": [
    "print(\"3시간 놀면 행복지수는\",sess.run(3*W))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = [[0,0],[0,1],[1,0],[1,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32,[None,2])\n",
    "W =  tf.Variable([[2.],[4.]],name=\"wieght\")\n",
    "b=tf.Variable([1.],name=\"bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = tf.matmul(X,W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.]\n",
      " [4.]]\n",
      "[[1.]\n",
      " [5.]\n",
      " [3.]\n",
      " [7.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(W))\n",
    "    print(sess.run(hypothesis,feed_dict={X:X_data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정답 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = [[1,1]]\n",
    "Y_data = [[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32,[None,2])\n",
    "Y = tf.placeholder(tf.float32,[None,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "W =  tf.Variable([[2.],[4.]],name=\"wieght\")\n",
    "b=tf.Variable([1.],name=\"bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = tf.matmul(X,W)+b\n",
    "cost = tf.square(hypothesis-Y)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [[2. 4.]] b: [1.] cost:  [[36.]]\n",
      "W: [[0.79999995 2.8       ]] b: [-0.20000005] cost:  [[5.7599993]]\n",
      "W: [[0.31999996 2.32      ]] b: [-0.68000007] cost:  [[0.9215996]]\n",
      "W: [[0.128 2.128]] b: [-0.87200004] cost:  [[0.14745605]]\n",
      "W: [[0.05119999 2.0512    ]] b: [-0.9488] cost:  [[0.02359288]]\n",
      "W: [[0.02048005 2.02048   ]] b: [-0.97951996] cost:  [[0.00377489]]\n",
      "W: [[0.00819202 2.0081918 ]] b: [-0.991808] cost:  [[0.00060398]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(7):\n",
    "        W_val,b_val,cost_val = sess.run([W,b,cost],\n",
    "                                       feed_dict={X:X_data,Y:Y_data})\n",
    "        sess.run(train,feed_dict={X:X_data,Y:Y_data})\n",
    "        print(\"W:\",W_val.reshape(1,2), \"b:\",b_val,\"cost: \",cost_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AND Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = [[0,0],[0,1],[1,0],[1,1]]\n",
    "Y_data = [[0],[0],[0],[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32,[None,2])\n",
    "Y = tf.placeholder(tf.float32,[None,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "W =  tf.Variable([[2.],[4.]],name=\"wieght\")\n",
    "b=tf.Variable([1.],name=\"bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = tf.matmul(X,W)+b\n",
    "cost = tf.square(hypothesis-Y)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train = optimizer.minimize(cost)\n",
    "predicted = tf.cast(hypothesis>0.5,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [[0.5000001 0.5000001]] b: [-0.25000012] cost: [[0.06250006]\n",
      " [0.0625    ]\n",
      " [0.0625    ]\n",
      " [0.06249994]] hypothesis:  [[-0.25000012]\n",
      " [ 0.25      ]\n",
      " [ 0.25      ]\n",
      " [ 0.7500001 ]] predicted:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(1000):\n",
    "        sess.run(train,feed_dict={X:X_data,Y:Y_data})\n",
    "        W_val, b_val, cost_val, hyp_val,pre_val = sess.run(\n",
    "        [W,b,cost,hypothesis,predicted],feed_dict={X:X_data,Y:Y_data}\n",
    "        )\n",
    "    print(\"W:\", W_val.reshape(1,2),\"b:\",b_val,\"cost:\",cost_val,\"hypothesis: \",hyp_val,\"predicted: \",pre_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = [[0,0],[0,1],[1,0],[1,1]]\n",
    "Y_data = [[0],[0],[0],[1]]\n",
    "X = tf.placeholder(tf.float32,[None,2])\n",
    "Y = tf.placeholder(tf.float32,[None,1])\n",
    "W =  tf.Variable([[2.],[4.]],name=\"wieght\")\n",
    "b=tf.Variable([1.],name=\"bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = tf.sigmoid(tf.matmul(X,W)+b) \n",
    "# cost = tf.square(hypothesis-Y)\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis)+(1-Y)*tf.log(1-hypothesis))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train = optimizer.minimize(cost)\n",
    "predicted = tf.cast(hypothesis>0.5,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [[3.3827615 3.4324124]] b: [-5.3185835] cost:  0.12072968 hypothesis:  [[0.0048758 ]\n",
      " [0.13168165]\n",
      " [0.12610757]\n",
      " [0.8170654 ]] predicted:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(1000):\n",
    "        sess.run(train,feed_dict={X:X_data,Y:Y_data})\n",
    "        W_val, b_val, cost_val, hyp_val,pre_val = sess.run(\n",
    "        [W,b,cost,hypothesis,predicted],feed_dict={X:X_data,Y:Y_data}\n",
    "        )\n",
    "    print(\"W:\", W_val.reshape(1,2),\"b:\",b_val,\"cost: \",cost_val,\"hypothesis: \",hyp_val,\"predicted: \",pre_val) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6590011388859679"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(2) / (np.exp(2)+np.exp(1)+np.exp(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2424329707047139"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(1) / (np.exp(2)+np.exp(1)+np.exp(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09856589040931818"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(0.1) / (np.exp(2)+np.exp(1)+np.exp(0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### argmax는 첫번째 파라미터의 최대값의 인덱스를 반환한다. 두번째 파라미터는 axis 값이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 7.617276\n",
      "200 0.5760485\n",
      "400 0.46889427\n",
      "600 0.39161724\n",
      "800 0.3201337\n",
      "1000 0.24982867\n",
      "1200 0.22186035\n",
      "1400 0.2021348\n",
      "1600 0.18552387\n",
      "1800 0.1713487\n",
      "2000 0.15911701\n",
      "--------------\n",
      "[[9.63493437e-03 9.90354061e-01 1.10147985e-05]] [1] w_val: [[-3.1963801   1.3862532   3.7835743 ]\n",
      " [-1.437983   -1.0502657  -0.24418539]\n",
      " [ 3.979966   -0.49463877 -2.5772676 ]\n",
      " [-1.7584865   0.9929392  -0.60073036]]\n",
      "--------------\n",
      "[[0.8072407  0.17068322 0.02207607]] [0]\n",
      "--------------\n",
      "[[1.6381939e-08 3.8557901e-04 9.9961436e-01]] [2]\n",
      "--------------\n",
      "[[9.63493437e-03 9.90354061e-01 1.10147985e-05]\n",
      " [8.07240725e-01 1.70683220e-01 2.20760740e-02]\n",
      " [1.63819394e-08 3.85579013e-04 9.99614358e-01]] [1 0 2]\n"
     ]
    }
   ],
   "source": [
    "# Lab 6 Softmax Classifier\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "\n",
    "\n",
    "x_data = [[1, 2, 1, 1],\n",
    "\n",
    "          [2, 1, 3, 2],\n",
    "\n",
    "          [3, 1, 3, 4],\n",
    "\n",
    "          [4, 1, 5, 5],\n",
    "\n",
    "          [1, 7, 5, 5],\n",
    "\n",
    "          [1, 2, 5, 6],\n",
    "\n",
    "          [1, 6, 6, 6],\n",
    "\n",
    "          [1, 7, 7, 7]]\n",
    "\n",
    "y_data = [[0, 0, 1],\n",
    "\n",
    "          [0, 0, 1],\n",
    "\n",
    "          [0, 0, 1],\n",
    "\n",
    "          [0, 1, 0],\n",
    "\n",
    "          [0, 1, 0],\n",
    "\n",
    "          [0, 1, 0],\n",
    "\n",
    "          [1, 0, 0],\n",
    "\n",
    "          [1, 0, 0]]\n",
    "\n",
    "\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 4])\n",
    "Y = tf.placeholder(\"float\", [None, 3])\n",
    "\n",
    "nb_classes = 3\n",
    "\n",
    "W = tf.Variable(tf.random_normal([4, nb_classes]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([nb_classes]), name='bias')\n",
    "\n",
    "# tf.nn.softmax computes softmax activations\n",
    "# softmax = exp(logits) / reduce_sum(exp(logits), dim)\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "# Cross entropy cost/loss\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# #accuracy 구하기\n",
    "# pred = tf.equal(tf.arg_max(hypothesis,1),tf.arg_max(Y,1))\n",
    "# accuracy = tf.reduce_mean(tf.cast(pred,tf.float32))\n",
    "# Launch graph\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(2001):\n",
    "        sess.run(optimizer, feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 200 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n",
    "    print('--------------')\n",
    "\n",
    "    # Testing & One-hot encoding\n",
    "    W_val, a = sess.run([W,hypothesis], feed_dict={X: [[1, 11, 7, 9]]})\n",
    "    print(a, sess.run(tf.argmax(a, 1)),'w_val:',W_val)\n",
    "    print('--------------')\n",
    "\n",
    "    b = sess.run(hypothesis, feed_dict={X: [[1, 3, 4, 3]]})\n",
    "    print(b, sess.run(tf.argmax(b, 1)))\n",
    "    print('--------------')\n",
    "\n",
    "    c = sess.run(hypothesis, feed_dict={X: [[1, 1, 0, 1]]})\n",
    "    print(c, sess.run(tf.argmax(c, 1)))\n",
    "    print('--------------')\n",
    "\n",
    "    all = sess.run(hypothesis, feed_dict={\n",
    "                   X: [[1, 11, 7, 9], [1, 3, 4, 3], [1, 1, 0, 1]]})\n",
    "    print(all, sess.run(tf.argmax(all, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'mul_6:0' shape=(?, 3) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y * tf.log(hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Decent Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\p\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "X_data = np.array([1])\n",
    "Y_data = np.array([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32,[1])\n",
    "Y = tf.placeholder(tf.float32,[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable([10.],name='weight')\n",
    "hypothesis = X*W\n",
    "cost = tf.square(hypothesis-Y)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 1 cost : [64.] W : [10.]\n",
      "step : 2 cost : [40.959995] W : [8.4]\n",
      "step : 3 cost : [26.2144] W : [7.12]\n",
      "step : 4 cost : [16.777214] W : [6.0959997]\n",
      "step : 5 cost : [10.737416] W : [5.2767997]\n",
      "step : 6 cost : [6.8719473] W : [4.62144]\n",
      "step : 7 cost : [4.3980455] W : [4.0971518]\n",
      "step : 8 cost : [2.8147495] W : [3.6777215]\n",
      "step : 9 cost : [1.8014395] W : [3.3421772]\n",
      "step : 10 cost : [1.1529212] W : [3.0737417]\n",
      "step : 11 cost : [0.7378695] W : [2.8589933]\n",
      "step : 12 cost : [0.4722364] W : [2.6871946]\n",
      "step : 13 cost : [0.3022312] W : [2.5497556]\n",
      "step : 14 cost : [0.19342804] W : [2.4398046]\n",
      "step : 15 cost : [0.12379391] W : [2.3518436]\n",
      "step : 16 cost : [0.07922808] W : [2.2814748]\n",
      "step : 17 cost : [0.05070599] W : [2.22518]\n",
      "step : 18 cost : [0.0324518] W : [2.1801438]\n",
      "step : 19 cost : [0.02076912] W : [2.144115]\n",
      "step : 20 cost : [0.01329226] W : [2.115292]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    feed_dict={X:X_data,Y:Y_data}\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(20):\n",
    "        cost_val,W_val = sess.run([cost,W],feed_dict=feed_dict)\n",
    "        sess.run(train, feed_dict=feed_dict)\n",
    "        print(\"step :\",step+1,\"cost :\" ,cost_val,\"W :\",W_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\p\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-bd345c99f20d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mY_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "X_data = [[1,2]]\n",
    "Y_data = [[1,0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(\"float32\", [None, 2])\n",
    "Y = tf.placeholder(\"float32\", [None, 2])\n",
    "\n",
    "nb_classes = 3\n",
    "\n",
    "W = tf.Variable([[1.,2.],[3.,4.]], name='weight')\n",
    "b = tf.Variable([1.,2.], name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = tf.nn.softmax(tf.matmul(X,W) + b)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(hypothesis),axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 1 \n",
      "W: [[1. 2.]\n",
      " [3. 4.]] \n",
      "b:  [1. 2.] \n",
      "cost: 4.01815 \n",
      "hypothesis :\n",
      " [[0.018 0.982]] \n",
      "predicted\n",
      " [1]\n",
      "--------------------\n",
      "step : 2 \n",
      "W: [[1.0982 1.9018]\n",
      " [3.1964 3.8036]] \n",
      "b:  [1.0982 1.9018] \n",
      "cost: 2.879391 \n",
      "hypothesis :\n",
      " [[0.0562 0.9438]] \n",
      "predicted\n",
      " [1]\n",
      "--------------------\n",
      "step : 3 \n",
      "W: [[1.1926 1.8074]\n",
      " [3.3852 3.6148]] \n",
      "b:  [1.1926 1.8074] \n",
      "cost: 1.8584803 \n",
      "hypothesis :\n",
      " [[0.1559 0.8441]] \n",
      "predicted\n",
      " [1]\n",
      "--------------------\n",
      "step : 4 \n",
      "W: [[1.277 1.723]\n",
      " [3.554 3.446]] \n",
      "b:  [1.277 1.723] \n",
      "cost: 1.0872645 \n",
      "hypothesis :\n",
      " [[0.3371 0.6629]] \n",
      "predicted\n",
      " [1]\n",
      "--------------------\n",
      "step : 5 \n",
      "W: [[1.3433 1.6567]\n",
      " [3.6866 3.3134]] \n",
      "b:  [1.3433 1.6567] \n",
      "cost: 0.63524795 \n",
      "hypothesis :\n",
      " [[0.5298 0.4702]] \n",
      "predicted\n",
      " [0]\n",
      "--------------------\n",
      "step : 6 \n",
      "W: [[1.3903 1.6097]\n",
      " [3.7806 3.2194]] \n",
      "b:  [1.3903 1.6097] \n",
      "cost: 0.40865976 \n",
      "hypothesis :\n",
      " [[0.6645 0.3355]] \n",
      "predicted\n",
      " [0]\n",
      "--------------------\n",
      "step : 7 \n",
      "W: [[1.4238 1.5762]\n",
      " [3.8477 3.1523]] \n",
      "b:  [1.4238 1.5762] \n",
      "cost: 0.29081345 \n",
      "hypothesis :\n",
      " [[0.7477 0.2523]] \n",
      "predicted\n",
      " [0]\n",
      "--------------------\n",
      "step : 8 \n",
      "W: [[1.4491 1.5509]\n",
      " [3.8982 3.1018]] \n",
      "b:  [1.4491 1.5509] \n",
      "cost: 0.22261134 \n",
      "hypothesis :\n",
      " [[0.8004 0.1996]] \n",
      "predicted\n",
      " [0]\n",
      "--------------------\n",
      "step : 9 \n",
      "W: [[1.469  1.531 ]\n",
      " [3.9381 3.0619]] \n",
      "b:  [1.469 1.531] \n",
      "cost: 0.17917848 \n",
      "hypothesis :\n",
      " [[0.836 0.164]] \n",
      "predicted\n",
      " [0]\n",
      "--------------------\n",
      "step : 10 \n",
      "W: [[1.4854 1.5146]\n",
      " [3.9709 3.0291]] \n",
      "b:  [1.4854 1.5146] \n",
      "cost: 0.14942771 \n",
      "hypothesis :\n",
      " [[0.8612 0.1388]] \n",
      "predicted\n",
      " [0]\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10):\n",
    "        cost_val, W_val, b_val , hyp_val= sess.run([cost,W,b,hypothesis],feed_dict={X:X_data,Y:Y_data})\n",
    "        pred = sess.run(tf.argmax(hyp_val,1))\n",
    "        print(\"step :\",step+1,'\\nW:',np.round(W_val,4),'\\nb: ',np.round(b_val,4),\n",
    "        '\\ncost:',cost_val,'\\nhypothesis :\\n',np.round(hyp_val,4),'\\npredicted\\n',pred)\n",
    "        print('-'*20)\n",
    "        sess.run(train,feed_dict={X:X_data,Y:Y_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = [[0,0],[1,0],[0,1],[1,1]]\n",
    "Y_data = [[1,0],[1,0],[1,0],[0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(\"float32\", [None, 2])\n",
    "Y = tf.placeholder(\"float32\", [None, 2])\n",
    "\n",
    "\n",
    "W = tf.Variable([[1.,2.],[3.,4.]], name='weight')\n",
    "b = tf.Variable([[1.,2.]], name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = tf.nn.softmax(tf.matmul(X,W) + b)\n",
    "# cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(hypothesis),axis=1))\n",
    "cost=tf.nn.softmax_cross_entropy_with_logits_v2(logits=tf.matmul(X,W) + b,labels=Y)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 1 \n",
      "W: [[1. 2.]\n",
      " [3. 4.]] \n",
      "b:  [[1. 2.]] \n",
      "cost: [1.3132616  2.126928   2.126928   0.04858733] \n",
      "hypothesis :\n",
      " [[0.2689 0.7311]\n",
      " [0.1192 0.8808]\n",
      " [0.1192 0.8808]\n",
      " [0.0474 0.9526]] \n",
      "predicted\n",
      " [1 1 1 1]\n",
      "--------------------\n",
      "step : 2 \n",
      "W: [[1.8334 1.1666]\n",
      " [3.8334 3.1666]] \n",
      "b:  [[ 3.4452 -0.4452]] \n",
      "cost: [0.02023003 0.01043684 0.01043684 5.2293096 ] \n",
      "hypothesis :\n",
      " [[0.98   0.02  ]\n",
      " [0.9896 0.0104]\n",
      " [0.9896 0.0104]\n",
      " [0.9946 0.0054]] \n",
      "predicted\n",
      " [0 0 0 0]\n",
      "--------------------\n",
      "step : 3 \n",
      "W: [[0.8491 2.1509]\n",
      " [2.8491 4.1509]] \n",
      "b:  [[2.4914 0.5086]] \n",
      "cost: [0.12899974 0.4095395  0.4095395  0.43016562] \n",
      "hypothesis :\n",
      " [[0.879  0.121 ]\n",
      " [0.664  0.336 ]\n",
      " [0.664  0.336 ]\n",
      " [0.3496 0.6504]] \n",
      "predicted\n",
      " [0 0 0 1]\n",
      "--------------------\n",
      "step : 4 \n",
      "W: [[0.8356 2.1644]\n",
      " [2.8356 4.1644]] \n",
      "b:  [[2.9349 0.0651]] \n",
      "cost: [0.05516155 0.19407661 0.19407651 0.80475914] \n",
      "hypothesis :\n",
      " [[0.9463 0.0537]\n",
      " [0.8236 0.1764]\n",
      " [0.8236 0.1764]\n",
      " [0.5528 0.4472]] \n",
      "predicted\n",
      " [0 0 0 0]\n",
      "--------------------\n",
      "step : 5 \n",
      "W: [[0.4592 2.5408]\n",
      " [2.4592 4.5408]] \n",
      "b:  [[2.7886 0.2114]] \n",
      "cost: [0.0732429  0.47579953 0.47579938 0.18622524] \n",
      "hypothesis :\n",
      " [[0.9294 0.0706]\n",
      " [0.6214 0.3786]\n",
      " [0.6214 0.3786]\n",
      " [0.1699 0.8301]] \n",
      "predicted\n",
      " [0 0 0 1]\n",
      "--------------------\n",
      "step : 6 \n",
      "W: [[0.6679 2.3321]\n",
      " [2.6679 4.3321]] \n",
      "b:  [[ 3.4465 -0.4465]] \n",
      "cost: [0.0201791  0.10225607 0.10225607 1.0146627 ] \n",
      "hypothesis :\n",
      " [[0.98   0.02  ]\n",
      " [0.9028 0.0972]\n",
      " [0.9028 0.0972]\n",
      " [0.6375 0.3625]] \n",
      "predicted\n",
      " [0 0 0 0]\n",
      "--------------------\n",
      "step : 7 \n",
      "W: [[0.1276 2.8724]\n",
      " [2.1276 4.8724]] \n",
      "b:  [[ 3.0234 -0.0234]] \n",
      "cost: [0.04641617 0.5535158  0.5535158  0.08334046] \n",
      "hypothesis :\n",
      " [[0.9546 0.0454]\n",
      " [0.5749 0.4251]\n",
      " [0.5749 0.4251]\n",
      " [0.08   0.92  ]] \n",
      "predicted\n",
      " [0 0 0 1]\n",
      "--------------------\n",
      "step : 8 \n",
      "W: [[0.4727 2.5273]\n",
      " [2.4727 4.5273]] \n",
      "b:  [[ 3.8389 -0.8389]] \n",
      "cost: [0.0092556  0.07005205 0.07005205 1.0173763 ] \n",
      "hypothesis :\n",
      " [[0.9908 0.0092]\n",
      " [0.9323 0.0677]\n",
      " [0.9323 0.0677]\n",
      " [0.6385 0.3615]] \n",
      "predicted\n",
      " [0 0 0 0]\n",
      "--------------------\n",
      "step : 9 \n",
      "W: [[-0.0981  3.0981]\n",
      " [ 1.9019  5.0981]] \n",
      "b:  [[ 3.345 -0.345]] \n",
      "cost: [0.02466468 0.4764186  0.4764186  0.06489211] \n",
      "hypothesis :\n",
      " [[0.9756 0.0244]\n",
      " [0.621  0.379 ]\n",
      " [0.621  0.379 ]\n",
      " [0.0628 0.9372]] \n",
      "predicted\n",
      " [0 0 0 1]\n",
      "--------------------\n",
      "step : 10 \n",
      "W: [[0.2181 2.7819]\n",
      " [2.2181 4.7819]] \n",
      "b:  [[ 4.0645 -1.0645]] \n",
      "cost: [0.00590461 0.07409086 0.07409086 0.6937987 ] \n",
      "hypothesis :\n",
      " [[0.9941 0.0059]\n",
      " [0.9286 0.0714]\n",
      " [0.9286 0.0714]\n",
      " [0.5003 0.4997]] \n",
      "predicted\n",
      " [0 0 0 0]\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10):\n",
    "        cost_val, W_val, b_val , hyp_val= sess.run([cost,W,b,hypothesis],feed_dict={X:X_data,Y:Y_data})\n",
    "        pred = sess.run(tf.argmax(hyp_val,1))\n",
    "        print(\"step :\",step+1,'\\nW:',np.round(W_val,4),'\\nb: ',np.round(b_val,4),\n",
    "        '\\ncost:',cost_val,'\\nhypothesis :\\n',np.round(hyp_val,4),'\\npredicted\\n',pred)\n",
    "        print('-'*20)\n",
    "        sess.run(train,feed_dict={X:X_data,Y:Y_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(\"float32\", [None, 2])\n",
    "Y = tf.placeholder(\"float32\", [None, 2])\n",
    "\n",
    "\n",
    "W = tf.Variable([[1.,2.],[3.,4.]], name='weight')\n",
    "b = tf.Variable([[1.,2.],[1.,2.],[1.,2.],[1.,2.]], name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = tf.nn.softmax(tf.matmul(X,W) + b)\n",
    "cost = -tf.reduce_sum(Y*tf.log(hypothesis),axis=1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 1 \n",
      "W: [[1. 2.]\n",
      " [3. 4.]] \n",
      "b:  [[1. 2.]\n",
      " [1. 2.]\n",
      " [1. 2.]\n",
      " [1. 2.]] \n",
      "cost: [1.3132616  2.126928   2.126928   0.04858734] \n",
      "hypothesis :\n",
      " [[0.2689 0.7311]\n",
      " [0.1192 0.8808]\n",
      " [0.1192 0.8808]\n",
      " [0.0474 0.9526]] \n",
      "predicted\n",
      " [1 1 1 1]\n",
      "--------------------\n",
      "step : 2 \n",
      "W: [[1.8334 1.1666]\n",
      " [3.8334 3.1666]] \n",
      "b:  [[1.7311 1.2689]\n",
      " [1.8808 1.1192]\n",
      " [1.8808 1.1192]\n",
      " [0.9526 2.0474]] \n",
      "cost: [0.4885484  0.21487533 0.21487533 0.8195651 ] \n",
      "hypothesis :\n",
      " [[0.6135 0.3865]\n",
      " [0.8066 0.1934]\n",
      " [0.8066 0.1934]\n",
      " [0.5594 0.4406]] \n",
      "predicted\n",
      " [0 0 0 0]\n",
      "--------------------\n",
      "step : 3 \n",
      "W: [[1.4674 1.5326]\n",
      " [3.4674 3.5326]] \n",
      "b:  [[2.1175 0.8825]\n",
      " [2.0742 0.9258]\n",
      " [2.0742 0.9258]\n",
      " [0.3932 2.6068]] \n",
      "cost: [0.25526997 0.2916042  0.29160428 0.09159819] \n",
      "hypothesis :\n",
      " [[0.7747 0.2253]\n",
      " [0.7471 0.2529]\n",
      " [0.7471 0.2529]\n",
      " [0.0875 0.9125]] \n",
      "predicted\n",
      " [0 0 0 1]\n",
      "--------------------\n",
      "step : 4 \n",
      "W: [[1.6328 1.3672]\n",
      " [3.6328 3.3672]] \n",
      "b:  [[2.3428 0.6572]\n",
      " [2.3271 0.6729]\n",
      " [2.3271 0.6729]\n",
      " [0.3057 2.6943]] \n",
      "cost: [0.17001298 0.13684525 0.13684525 0.14500329] \n",
      "hypothesis :\n",
      " [[0.8437 0.1563]\n",
      " [0.8721 0.1279]\n",
      " [0.8721 0.1279]\n",
      " [0.135  0.865 ]] \n",
      "predicted\n",
      " [0 0 0 1]\n",
      "--------------------\n",
      "step : 5 \n",
      "W: [[1.6257 1.3743]\n",
      " [3.6257 3.3743]] \n",
      "b:  [[2.4992 0.5008]\n",
      " [2.455  0.545 ]\n",
      " [2.455  0.545 ]\n",
      " [0.1707 2.8293]] \n",
      "cost: [0.12712331 0.10900957 0.10900957 0.109568  ] \n",
      "hypothesis :\n",
      " [[0.8806 0.1194]\n",
      " [0.8967 0.1033]\n",
      " [0.8967 0.1033]\n",
      " [0.1038 0.8962]] \n",
      "predicted\n",
      " [0 0 0 1]\n",
      "--------------------\n",
      "step : 6 \n",
      "W: [[1.6252 1.3748]\n",
      " [3.6252 3.3748]] \n",
      "b:  [[2.6186 0.3814]\n",
      " [2.5583 0.4417]\n",
      " [2.5583 0.4417]\n",
      " [0.0669 2.9331]] \n",
      "cost: [0.10144253 0.08963341 0.08963354 0.08975265] \n",
      "hypothesis :\n",
      " [[0.9035 0.0965]\n",
      " [0.9143 0.0857]\n",
      " [0.9143 0.0857]\n",
      " [0.0858 0.9142]] \n",
      "predicted\n",
      " [0 0 0 1]\n",
      "--------------------\n",
      "step : 7 \n",
      "W: [[1.6251 1.3749]\n",
      " [3.6251 3.3749]] \n",
      "b:  [[ 2.715   0.285 ]\n",
      " [ 2.644   0.356 ]\n",
      " [ 2.644   0.356 ]\n",
      " [-0.0189  3.0189]] \n",
      "cost: [0.08437119 0.07604802 0.07604802 0.07608597] \n",
      "hypothesis :\n",
      " [[0.9191 0.0809]\n",
      " [0.9268 0.0732]\n",
      " [0.9268 0.0732]\n",
      " [0.0733 0.9267]] \n",
      "predicted\n",
      " [0 0 0 1]\n",
      "--------------------\n",
      "step : 8 \n",
      "W: [[1.625 1.375]\n",
      " [3.625 3.375]] \n",
      "b:  [[ 2.7959  0.2041]\n",
      " [ 2.7172  0.2828]\n",
      " [ 2.7172  0.2828]\n",
      " [-0.0922  3.0922]] \n",
      "cost: [0.07220914 0.06602608 0.06602608 0.06604117] \n",
      "hypothesis :\n",
      " [[0.9303 0.0697]\n",
      " [0.9361 0.0639]\n",
      " [0.9361 0.0639]\n",
      " [0.0639 0.9361]] \n",
      "predicted\n",
      " [0 0 0 1]\n",
      "--------------------\n",
      "step : 9 \n",
      "W: [[1.625 1.375]\n",
      " [3.625 3.375]] \n",
      "b:  [[ 2.8656  0.1344]\n",
      " [ 2.7811  0.2189]\n",
      " [ 2.7811  0.2189]\n",
      " [-0.1561  3.1561]] \n",
      "cost: [0.06310757 0.0583335  0.0583335  0.05834058] \n",
      "hypothesis :\n",
      " [[0.9388 0.0612]\n",
      " [0.9433 0.0567]\n",
      " [0.9433 0.0567]\n",
      " [0.0567 0.9433]] \n",
      "predicted\n",
      " [0 0 0 1]\n",
      "--------------------\n",
      "step : 10 \n",
      "W: [[1.625 1.375]\n",
      " [3.625 3.375]] \n",
      "b:  [[ 2.9268  0.0732]\n",
      " [ 2.8378  0.1622]\n",
      " [ 2.8378  0.1622]\n",
      " [-0.2128  3.2128]] \n",
      "cost: [0.05604169 0.05224442 0.05224442 0.052248  ] \n",
      "hypothesis :\n",
      " [[0.9455 0.0545]\n",
      " [0.9491 0.0509]\n",
      " [0.9491 0.0509]\n",
      " [0.0509 0.9491]] \n",
      "predicted\n",
      " [0 0 0 1]\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10):\n",
    "        cost_val, W_val, b_val , hyp_val= sess.run([cost,W,b,hypothesis],feed_dict={X:X_data,Y:Y_data})\n",
    "        pred = sess.run(tf.argmax(hyp_val,1))\n",
    "        print(\"step :\",step+1,'\\nW:',np.round(W_val,4),'\\nb: ',np.round(b_val,4),\n",
    "        '\\ncost:',cost_val,'\\nhypothesis :\\n',np.round(hyp_val,4),'\\npredicted\\n',pred)\n",
    "        print('-'*20)\n",
    "        sess.run(train,feed_dict={X:X_data,Y:Y_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
