{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\p\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 15        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 33\n",
      "Trainable params: 33\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.470563  , 0.6424935 , 0.48684376]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(2,input_shape=(2,)))\n",
    "model.add(Dense(4))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.predict(np.array([[1.,2.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.loadtxt('zoo.csv',delimiter=',',dtype=np.float32)\n",
    "x= xy[:,0:-1]\n",
    "y=xy[:,[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 1., 0., 1.],\n",
       "       [0., 0., 1., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 1., 0., 1.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [3.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [3.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [5.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [1.],\n",
       "       [5.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [6.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [6.],\n",
       "       [3.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [6.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [6.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [6.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [5.],\n",
       "       [0.],\n",
       "       [6.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = int(y.max()+1)\n",
    "y_one_hot = np_utils.to_categorical(y,nb_classes)\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y_one_hot,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 2.2944 - acc: 0.0714\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 0s 71us/step - loss: 1.6269 - acc: 0.4143\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 0s 100us/step - loss: 1.2831 - acc: 0.6143\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 0s 100us/step - loss: 1.0581 - acc: 0.7143\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.9097 - acc: 0.7429\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 0s 100us/step - loss: 0.7872 - acc: 0.7571\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 0s 86us/step - loss: 0.6826 - acc: 0.8000\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 0s 114us/step - loss: 0.5949 - acc: 0.8143\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 0s 114us/step - loss: 0.5250 - acc: 0.8143\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 0s 114us/step - loss: 0.4640 - acc: 0.8286\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 0s 114us/step - loss: 0.4123 - acc: 0.8429\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 0s 99us/step - loss: 0.3655 - acc: 0.8429\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 0s 100us/step - loss: 0.3289 - acc: 0.8714\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.2983 - acc: 0.9286\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 0s 100us/step - loss: 0.2683 - acc: 0.9000\n",
      "Epoch 16/100\n",
      "70/70 [==============================] - 0s 114us/step - loss: 0.2396 - acc: 0.9429\n",
      "Epoch 17/100\n",
      "70/70 [==============================] - 0s 114us/step - loss: 0.2168 - acc: 0.9429\n",
      "Epoch 18/100\n",
      "70/70 [==============================] - 0s 100us/step - loss: 0.1964 - acc: 0.9571\n",
      "Epoch 19/100\n",
      "70/70 [==============================] - 0s 128us/step - loss: 0.1744 - acc: 0.9571\n",
      "Epoch 20/100\n",
      "70/70 [==============================] - 0s 128us/step - loss: 0.1528 - acc: 0.9571\n",
      "Epoch 21/100\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.1363 - acc: 0.9714\n",
      "Epoch 22/100\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.1216 - acc: 0.9857\n",
      "Epoch 23/100\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.1141 - acc: 0.9857\n",
      "Epoch 24/100\n",
      "70/70 [==============================] - 0s 100us/step - loss: 0.1060 - acc: 0.9857\n",
      "Epoch 25/100\n",
      "70/70 [==============================] - 0s 114us/step - loss: 0.0956 - acc: 1.0000\n",
      "Epoch 26/100\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.0804 - acc: 1.0000\n",
      "Epoch 27/100\n",
      "70/70 [==============================] - 0s 128us/step - loss: 0.0777 - acc: 0.9857\n",
      "Epoch 28/100\n",
      "70/70 [==============================] - 0s 128us/step - loss: 0.0739 - acc: 0.9857\n",
      "Epoch 29/100\n",
      "70/70 [==============================] - 0s 100us/step - loss: 0.0665 - acc: 1.0000\n",
      "Epoch 30/100\n",
      "70/70 [==============================] - 0s 157us/step - loss: 0.0595 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.0551 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "70/70 [==============================] - 0s 128us/step - loss: 0.0518 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "70/70 [==============================] - 0s 86us/step - loss: 0.0459 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0421 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "70/70 [==============================] - 0s 100us/step - loss: 0.0396 - acc: 1.0000\n",
      "Epoch 36/100\n",
      "70/70 [==============================] - 0s 128us/step - loss: 0.0359 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "70/70 [==============================] - 0s 114us/step - loss: 0.0344 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.0329 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "70/70 [==============================] - 0s 100us/step - loss: 0.0298 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "70/70 [==============================] - 0s 114us/step - loss: 0.0268 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "70/70 [==============================] - 0s 114us/step - loss: 0.0256 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "70/70 [==============================] - 0s 100us/step - loss: 0.0252 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "70/70 [==============================] - 0s 142us/step - loss: 0.0229 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "70/70 [==============================] - 0s 128us/step - loss: 0.0218 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "70/70 [==============================] - 0s 100us/step - loss: 0.0208 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "70/70 [==============================] - 0s 100us/step - loss: 0.0204 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "70/70 [==============================] - 0s 114us/step - loss: 0.0203 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "70/70 [==============================] - 0s 114us/step - loss: 0.0187 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "70/70 [==============================] - 0s 142us/step - loss: 0.0165 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "70/70 [==============================] - 0s 100us/step - loss: 0.0147 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0141 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "70/70 [==============================] - 0s 128us/step - loss: 0.0138 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "70/70 [==============================] - 0s 100us/step - loss: 0.0145 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "70/70 [==============================] - 0s 142us/step - loss: 0.0137 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.0128 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0115 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "70/70 [==============================] - 0s 100us/step - loss: 0.0103 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "70/70 [==============================] - 0s 100us/step - loss: 0.0097 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "70/70 [==============================] - 0s 199us/step - loss: 0.0095 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.0092 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "70/70 [==============================] - 0s 100us/step - loss: 0.0090 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "70/70 [==============================] - 0s 114us/step - loss: 0.0089 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.0085 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.0081 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "70/70 [==============================] - 0s 128us/step - loss: 0.0076 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "70/70 [==============================] - 0s 100us/step - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "70/70 [==============================] - 0s 157us/step - loss: 0.0070 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "70/70 [==============================] - 0s 86us/step - loss: 0.0067 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.0064 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "70/70 [==============================] - 0s 114us/step - loss: 0.0061 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "70/70 [==============================] - 0s 114us/step - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.0055 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "70/70 [==============================] - 0s 128us/step - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "70/70 [==============================] - 0s 100us/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "70/70 [==============================] - 0s 100us/step - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "70/70 [==============================] - 0s 100us/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "70/70 [==============================] - 0s 114us/step - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "70/70 [==============================] - 0s 86us/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "70/70 [==============================] - 0s 128us/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "70/70 [==============================] - 0s 114us/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "70/70 [==============================] - 0s 71us/step - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "70/70 [==============================] - 0s 100us/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "70/70 [==============================] - 0s 157us/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "70/70 [==============================] - 0s 114us/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "70/70 [==============================] - 0s 171us/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "70/70 [==============================] - 0s 85us/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "70/70 [==============================] - 0s 128us/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "70/70 [==============================] - 0s 100us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "70/70 [==============================] - 0s 114us/step - loss: 0.0027 - acc: 1.0000\n",
      "31/31 [==============================] - 0s 2ms/step\n",
      "\n",
      "test: \n",
      " [0.5709825158119202, 0.9354838728904724]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12,input_dim=len(x[0])))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(nb_classes,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.01),metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs=100)\n",
    "# 실제 데이터에 넣어서 돌리기 때문에 acc와 loss 값이 다르다.\n",
    "print('\\ntest: \\n',model.evaluate(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam,RMSprop\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_CHANNELS = 3\n",
    "IMG_ROWS = 32\n",
    "IMG_COLS =32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "NB_EPOCH = 20\n",
    "NB_CLASSES = 10\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "OPTIM = Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 2022s 12us/step\n",
      "x_train shape:  (50000, 32, 32, 3)\n",
      "50000 train_samples\n",
      "10000 test_samples\n"
     ]
    }
   ],
   "source": [
    "(x_train,y_train), (x_test,y_test) = cifar10.load_data()\n",
    "print('x_train shape: ',x_train.shape)\n",
    "print(x_train.shape[0],'train_samples')\n",
    "print(x_test.shape[0],'test_samples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train,NB_CLASSES)\n",
    "y_test = np_utils.to_categorical(y_test,NB_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_29 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 10)                10250     \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 679,786\n",
      "Trainable params: 679,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= Sequential()\n",
    "model.add(Conv2D(32,(3,3),padding='same',input_shape=(IMG_ROWS,IMG_COLS,IMG_CHANNELS)))\n",
    "model.add(Activation('selu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(32,(3,3),padding='same'))\n",
    "model.add(Activation('selu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(32,(3,3),padding='same'))\n",
    "model.add(Activation('selu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(32,(3,3),padding='same'))\n",
    "model.add(Activation('selu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "# model.add(Conv2D(16,(3,3),padding='same',input_shape=(16,16,32)))\n",
    "# model.add(Activation('selu'))       \n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('selu'))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('selu'))\n",
    "model.add(Dense(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1024))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 106s 3ms/step - loss: 2.0396 - acc: 0.2557 - val_loss: 1.7718 - val_acc: 0.3318\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 103s 3ms/step - loss: 1.8011 - acc: 0.3359 - val_loss: 1.5321 - val_acc: 0.4404\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 104s 3ms/step - loss: 1.6820 - acc: 0.3828 - val_loss: 1.5437 - val_acc: 0.4299\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 104s 3ms/step - loss: 1.6078 - acc: 0.4096 - val_loss: 1.3889 - val_acc: 0.4925\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 104s 3ms/step - loss: 1.5560 - acc: 0.4341 - val_loss: 1.6876 - val_acc: 0.4172\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 104s 3ms/step - loss: 1.5100 - acc: 0.4514 - val_loss: 1.3405 - val_acc: 0.5186\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 104s 3ms/step - loss: 1.4715 - acc: 0.4718 - val_loss: 1.3848 - val_acc: 0.4919\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 104s 3ms/step - loss: 1.4514 - acc: 0.4800 - val_loss: 1.4402 - val_acc: 0.4658\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 104s 3ms/step - loss: 1.4221 - acc: 0.4887 - val_loss: 1.3371 - val_acc: 0.5251\n",
      "Epoch 10/20\n",
      "11008/40000 [=======>......................] - ETA: 1:09 - loss: 1.4142 - acc: 0.4923"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-6189ceb6579b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mOPTIM\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNB_EPOCH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mVALIDATION_SPLIT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mVERBOSE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1399\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1400\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer=OPTIM,metrics=['accuracy'])\n",
    "history = model.fit(x_train,y_train,batch_size=BATCH_SIZE,epochs=NB_EPOCH,validation_split=VALIDATION_SPLIT,verbose=VERBOSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n",
      "10000/10000 [==============================] - 7s 720us/step\n",
      "\n",
      "Test score:  1.2439868705749513\n",
      "\\Test accuracy 0.6137\n"
     ]
    }
   ],
   "source": [
    "print('Testing')\n",
    "score = model.evaluate(x_test,y_test,batch_size=BATCH_SIZE,verbose=VERBOSE)\n",
    "print('\\nTest score: ',score[0])\n",
    "print('\\Test accuracy',score[1])\n",
    "\n",
    "model_json = model.to_json()\n",
    "open('cifar10_architecture_adan.lyaer_512_3__selu.json','w').write(model_json)\n",
    "model.save_weights('cifar10_architecture_adan.lyaer_512_3__selu.json.h5',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'],loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'],loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
